{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Videos: time-series images \n",
    "\n",
    "Videos are collections of images (*spatial data types*) across temporal scale (*time-series*). Here we will explore videos of chicks that were turned into a single directory, stored in **imagedata**, of images that are ordered (and numbered) based on time. In this case, the first image represents the beginning of the video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extract 1 frame-per-second, maintain jpeg quality, and save all images in a single directory \n",
    "\n",
    "#! ffmpeg -i videodata/13B35A/0801_0841/00003.MTS -vf fps=1 -q:v 1 imagedata/13B35A/0801_0841/00003/img_%05d.jpg "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Import Requirements 1\n",
    "\n",
    "We can process, visualize, and train compute vision models (*deep learning / deep neural networks*) on time-series images sampled from videos. First, we need a few libraries for image processing and deep learning. \n",
    "\n",
    "### Step 1.1: Install keras \n",
    "\n",
    "*Keras* makes training, analyzing, and running deep learning models using TensorFlow fast and easy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/f3/413bab4ff08e1fc4828dfc59996d721917df8e8583ea85385d51125dceff/pip-19.0.3-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |################################| 1.4MB 1.2MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 8.1.1\n",
      "    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n",
      "Successfully installed pip-19.0.3\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.5/dist-packages (2.2.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras) (0.19.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.5/dist-packages (from keras) (1.0.9)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras) (5.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.5/dist-packages (from keras) (1.0.7)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras) (1.12.1)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install --upgrade pip\n",
    "\n",
    "! pip3 install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2: Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#import tensorflow as tf\n",
    "import math \n",
    "#import keras\n",
    "import pandas\n",
    "#import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#img_0801_ex = cv2.imread(\"imagedata/13B35A/0801_0841/00003/img_00001.jpg\")\n",
    "\n",
    "#cv2.imshow(\"Original Image\", img_0801_ex)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.3: Well...OpenCV is a nightmare right now...\n",
    "\n",
    "Switching to using the *Python Imaging Library* (**Pillow**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format: JPEG\n",
      "Size: (1920, 1080)\n",
      "Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "#! pip3 install Pillow\n",
    "\n",
    "from PIL import Image \n",
    "\n",
    "img_0801_ex = Image.open(\"imagedata/13B35A/0801_0841/00003/img_00001.jpg\")\n",
    "print(\"Format: {0}\\nSize: {1}\\nMode: {2}\".format(img_0801_ex.format, img_0801_ex.size, img_0801_ex.mode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotated Data for Classifying Allopreening Events 2  \n",
    "\n",
    "Time-series images, *i.e. frames of the videos*, are annotated with one of three classes: \n",
    "\n",
    "**hang** : birds are just hanging out! \n",
    "\n",
    "**selfp** : self-preening, as oppossed to allopreening ^__^\n",
    "\n",
    "**allop** : allopreening - a chick cleans another chick \n",
    "\n",
    "\n",
    "Each frame has one of these three classes (and only one at a time, for the time being). \n",
    "\n",
    "### Step 2.1: Overview of behaviors tagged in sample data \n",
    "\n",
    "In *nest13B30A - 0720_1030 - 00014*, there is a 36 second sample of the video, with 10 frames per second turned into images. Of these **362 images**, roughly a third are labeled with allopreening behavior (*allop*), another third are labeled with self-preening behavior (*selfp*), and the first third of the images had neither behavior present (*hang*). \n",
    "\n",
    "In *nest13B30A - 0801_0841 - 00003*, there is a 4 min and 30 sec sample of the video, with 1 frame per second turned into images. Of these **430 images**, roughly 160 images are labeled with allopreening behavior (*allop*), another ~140 images are labeled with self-preening behavior (*selfp*), and the remaining ~130 images are absent of cleaning. Gross.\n",
    "\n",
    "### Step 2.2: *FIXME - finish this section*\n",
    "\n",
    "To be developed\n",
    "\n",
    "## Manipulate Images and Gather Pixel Data 3\n",
    "\n",
    "There are several steps in prepping an image for deep learning or other computer vision algorithms / analyses. These steps are called **preprocessing** and they often take the second most amount of time...after actually gathering and/or generating annotated data. \n",
    "\n",
    "### Step 3.1: Utility functions for manipulating images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get size of image \n",
    "\n",
    "def get_img_size(image):\n",
    "    return image.size\n",
    "\n",
    "## Roll image sideways \n",
    "\n",
    "def roll_img(image, delta, xsize, ysize):\n",
    "    \"\"\"Rotate image through a two part crop-and-paste method\"\"\"\n",
    "    img_y_crop = image.crop((0, 0, delta, ysize))\n",
    "    img_x_crop = image.crop((delta, 0, xsize, ysize))\n",
    "     \n",
    "    image.paste(img_y_crop, ((xsize - delta), 0, xsize, ysize))\n",
    "    image.paste(img_x_crop, (0, 0, xsize - delta, ysize))\n",
    "    \n",
    "    return image\n",
    "    \n",
    "def roll_img_else_original_img(image, try_delta):\n",
    "    \"\"\"Check to see if image can be rolled. If True, call roll_img fn else return img\"\"\"\n",
    "    xsize, ysize = get_img_size(image)\n",
    "    return ((image) if ((try_delta % xsize) == 0) else (roll_img(image, try_delta, xsize, ysize)))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 1080)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_img_size(img_0801_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "roll_img_else_original_img(img_0801_ex, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future development \n",
    "\n",
    "**Label encoding** - need to encode labels (*i.e. classes*) to transcribe words into sparse matrices (*i.e. numbers that are very far apart in Euclidean space*) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allop  -->  0\n",
      "hang  -->  1\n",
      "selfp  -->  2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "label_encoder = LabelEncoder()\n",
    "input_classes = [\"hang\", \"selfp\", \"allop\"]\n",
    "label_encoder.fit(input_classes)\n",
    "\n",
    "for i, item in enumerate(label_encoder.classes_):\n",
    "    print(item, \" --> \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
